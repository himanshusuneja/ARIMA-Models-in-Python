{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Prelude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting AR and MA models\n",
    "\n",
    "In this exercise you will fit an AR and an MA model to some data. The data here has been generated using the arma_generate_sample() function we used before.\n",
    "\n",
    "You know the real AR and MA parameters used to create this data so it is a really good way to gain some confidence with ARMA models and know you are doing it right. In the next exercise you'll move onto some real world data with confidence.\n",
    "\n",
    "There is a pandas DataFrame available in your environment called sample. It has two columns of different time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame([-0.18, -0.25, -0.26, -0.28, -0.38, -0.01, 0.16, 0.3, 0.16, 0.1, 0.23, -0.06, 0.1, 0.2, -0.03, 0.09, -0.12, -0.3, 0.23, 0.3, 0.39, 0.1, -0.07, 0.04, -0.04, 0.42, 0.43, 0.57, 0.31, 0.12, -0.01, -0.29, -0.3, -0.2, -0.15, -0.25, -0.49, -0.24, -0.11, 0.28, 0.08, -0.05, -0.34, -0.23, 0.12, 0.15, 0.02, 0.02, 0.25, 0.32, -0.03, -0.54, -0.4, 0.03, -0.03, -0.23, -0.32, -0.17, -0.26, -0.5, -0.24, -0.2, -0.24, 0.03, 0.21, 0.25, 0.05, -0.27, 0.02, 0.5, 0.59, -0.12, -0.14, -0.02, 0.14, 0.13, -0.13, -0.37, 0.07, 0.12, 0.1, 0.28, 0.07, -0.27, -0.25, 0.04, -0.23, -0.51, -0.65, -0.17, 0.29, 0.69, 0.39, 0.38, 0.56, 0.27, 0.1, -0.09, 0.15, 0.09], columns = ['timeseries_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ARMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:           timeseries_1   No. Observations:                  100\n",
      "Model:                     ARMA(2, 0)   Log Likelihood                  18.233\n",
      "Method:                       css-mle   S.D. of innovations              0.201\n",
      "Date:                Wed, 26 Feb 2020   AIC                            -28.467\n",
      "Time:                        12:36:44   BIC                            -18.046\n",
      "Sample:                             0   HQIC                           -24.249\n",
      "                                                                              \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const               1.319e-05      0.039      0.000      1.000      -0.076       0.076\n",
      "ar.L1.timeseries_1     0.8183      0.093      8.759      0.000       0.635       1.001\n",
      "ar.L2.timeseries_1    -0.3367      0.093     -3.605      0.000      -0.520      -0.154\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            1.2153           -1.2220j            1.7234           -0.1254\n",
      "AR.2            1.2153           +1.2220j            1.7234            0.1254\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ARMA(sample['timeseries_1'], order=(2,0))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['timeseries_2'] = [-0.18, -0.12, -0.22, -0.17, -0.28, 0.15, -0.01, 0.33, -0.02, 0.12, 0.14, -0.16, 0.28, -0.02, -0.0, 0.17, -0.29, -0.08, 0.28, 0.02, 0.48, -0.17, 0.03, 0.01, -0.08, 0.53, 0.06, 0.61, -0.03, 0.18, -0.1, -0.23, -0.11, -0.16, -0.07, -0.19, -0.38, -0.04, -0.18, 0.4, -0.17, 0.1, -0.43, -0.0, 0.08, 0.08, 0.05, -0.01, 0.2, 0.18, -0.09, -0.43, -0.16, 0.02, -0.05, -0.1, -0.29, -0.07, -0.24, -0.32, -0.06, -0.28, -0.05, 0.06, 0.08, 0.21, -0.05, -0.23, 0.16, 0.33, 0.41, -0.25, 0.09, -0.21, 0.27, 0.05, -0.15, -0.26, 0.19, -0.09, 0.24, 0.16, -0.09, -0.14, -0.15, 0.05, -0.27, -0.26, -0.53, 0.06, 0.18, 0.6, 0.06, 0.41, 0.26, 0.1, 0.18, -0.2, 0.27, -0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ARMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:           timeseries_2   No. Observations:                  100\n",
      "Model:                     ARMA(0, 3)   Log Likelihood                  19.991\n",
      "Method:                       css-mle   S.D. of innovations              0.196\n",
      "Date:                Wed, 26 Feb 2020   AIC                            -29.982\n",
      "Time:                        12:38:32   BIC                            -16.956\n",
      "Sample:                             0   HQIC                           -24.710\n",
      "                                                                              \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.0015      0.029     -0.051      0.959      -0.058       0.055\n",
      "ma.L1.timeseries_2     0.1215      0.105      1.158      0.250      -0.084       0.327\n",
      "ma.L2.timeseries_2     0.6321      0.118      5.378      0.000       0.402       0.863\n",
      "ma.L3.timeseries_2    -0.2924      0.110     -2.668      0.009      -0.507      -0.078\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "MA.1           -0.2996           -1.0719j            1.1129           -0.2934\n",
      "MA.2           -0.2996           +1.0719j            1.1129            0.2934\n",
      "MA.3            2.7610           -0.0000j            2.7610           -0.0000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ARMA(sample['timeseries_2'], order=(0,3))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an ARMA model\n",
    "\n",
    "In this exercise you will fit an ARMA model to the earthquakes dataset. You saw before that the earthquakes dataset is stationary so you don't need to transform it at all. It comes ready for modeling straight out the ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               ARMA Model Results                               \n",
      "================================================================================\n",
      "Dep. Variable:     earthquakes_per_year   No. Observations:                   99\n",
      "Model:                       ARMA(3, 1)   Log Likelihood                -315.673\n",
      "Method:                         css-mle   S.D. of innovations              5.853\n",
      "Date:                  Wed, 26 Feb 2020   AIC                            643.345\n",
      "Time:                          12:46:19   BIC                            658.916\n",
      "Sample:                      01-01-1900   HQIC                           649.645\n",
      "                           - 01-01-1998                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "const                         19.6452      1.929     10.183      0.000      15.864      23.426\n",
      "ar.L1.earthquakes_per_year     0.5794      0.416      1.393      0.167      -0.236       1.394\n",
      "ar.L2.earthquakes_per_year     0.0251      0.208      0.121      0.904      -0.382       0.433\n",
      "ar.L3.earthquakes_per_year     0.1519      0.131      1.162      0.248      -0.104       0.408\n",
      "ma.L1.earthquakes_per_year    -0.1720      0.416     -0.413      0.680      -0.988       0.644\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            1.2047           -0.0000j            1.2047           -0.0000\n",
      "AR.2           -0.6850           -2.2352j            2.3378           -0.2973\n",
      "AR.3           -0.6850           +2.2352j            2.3378            0.2973\n",
      "MA.1            5.8139           +0.0000j            5.8139            0.0000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# # Instantiate the model\n",
    "# model = ARMA(earthquake, order=(3,1))\n",
    "\n",
    "# # Fit the model\n",
    "# results = model.fit()\n",
    "\n",
    "# # Print model fit summary\n",
    "# print(results.summary())\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Instantiate the model\n",
    "model = ARMA(earthquake, (3, 1))\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print model fit summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an ARMAX model\n",
    "\n",
    "In this exercise you will fit an ARMAX model to a time series which represents the wait times at an accident and emergency room for urgent medical care.\n",
    "\n",
    "The variable you would like to model is the wait times to be seen by a medical professional wait_times_hrs. This may be related to an exogenous variable that you measured nurse_count which is the number of nurses on shift at any given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital = pd.DataFrame([1.75, 1.66, 1.65, 1.62, 1.48, 1.77, 1.99, 2.17, 1.57, 1.28, 1.44, 1.06, 1.06, 1.2, 0.89, 1.04, 0.77, 0.54, 1.23, 1.33, 1.65, 1.27, 1.26, 1.4, 1.51, 2.13, 2.35, 2.53, 2.19, 1.72, 1.55, 1.19, 0.96, 1.1, 1.16, 1.03, 0.71, 0.82, 1.0, 1.51, 1.25, 1.07, 0.69, 1.26, 1.73, 1.76, 1.6, 1.59, 2.32, 2.41, 1.95, 1.06, 1.24, 1.61, 1.53, 1.26, 0.72, 0.71, 0.59, 0.26, 0.61, 0.66, 0.61, 0.97, 1.2, 1.26, 1.0, 0.58, 1.17, 1.81, 2.13, 1.19, 1.38, 1.54, 1.75, 1.74, 1.39, 0.87, 1.66, 1.72, 1.48, 1.73, 1.45, 1.0, 1.23, 1.4, 1.05, 0.67, 0.5, 1.13, 1.74, 2.69, 2.29, 2.28, 2.52, 1.92, 1.91, 1.66, 1.98, 1.9, 1.4, 1.01, 1.21, 1.46, 1.8, 1.3, 1.02, 1.46, 1.6, 1.63, 1.47, 1.37, 1.22, 1.38, 1.6, 2.44, 2.45, 2.02, 1.72, 1.49, 1.4, 1.32, 1.69, 2.01, 2.24, 1.86, 1.4, 1.67, 2.14, 1.51, 1.09, 1.24, 1.66, 1.28, 0.99, 1.15, 1.28, 0.96, 1.3, 1.28, 1.71, 1.56, 1.17, 1.36, 1.78, 2.08, 1.97, 2.0, 1.97, 2.02, 1.59, 1.21, 0.86, 0.19, 0.76, 1.08, 0.8, 0.57, 0.94, 1.37, 1.61, 1.96, 1.56, 1.1, 1.6, 1.71, 1.29, 1.55], columns = ['wait_times_hrs'])\n",
    "hospital['nurse_count'] = [1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 7.0, 9.0, 9.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 7.0, 7.0, 5.0, 5.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.0, 1.0, 1.0, 3.0, 3.0, 5.0, 5.0, 5.0, 9.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 9.0, 9.0, 7.0, 7.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ARMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:         wait_times_hrs   No. Observations:                  168\n",
      "Model:                     ARMA(2, 1)   Log Likelihood                 -11.817\n",
      "Method:                       css-mle   S.D. of innovations              0.259\n",
      "Date:                Wed, 26 Feb 2020   AIC                             35.634\n",
      "Time:                        13:19:11   BIC                             54.378\n",
      "Sample:                             0   HQIC                            43.242\n",
      "                                                                              \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    2.0995      0.086     24.311      0.000       1.930       2.269\n",
      "nurse_count             -0.1170      0.013     -9.057      0.000      -0.142      -0.092\n",
      "ar.L1.wait_times_hrs     0.5658      0.165      3.435      0.001       0.243       0.889\n",
      "ar.L2.wait_times_hrs    -0.1594      0.132     -1.209      0.228      -0.418       0.099\n",
      "ma.L1.wait_times_hrs     0.3762      0.157      2.388      0.018       0.067       0.685\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            1.7744           -1.7675j            2.5045           -0.1247\n",
      "AR.2            1.7744           +1.7675j            2.5045            0.1247\n",
      "MA.1           -2.6584           +0.0000j            2.6584            0.5000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ARMA(hospital[\"wait_times_hrs\"], order=(2,1), exog=hospital[\"nurse_count\"])\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Print model fit summary\n",
    "print(results.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating one-step-ahead predictions\n",
    "\n",
    "It is very hard to forecast stock prices. Classic economics actually tells us that this should be impossible because of market clearing.\n",
    "\n",
    "Your task in this exercise is to attempt the impossible and predict the Amazon stock price anyway.\n",
    "\n",
    "In this exercise you will generate one-step-ahead predictions for the stock price as well as the uncertainty of these predictions.\n",
    "\n",
    "A model has already been fitted to the Amazon data for you. The results object from this model is available in your environment as results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "one_step_forecast = results.get_prediction(start=-30)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean_forecast = one_step_forecast.predicted_mean\n",
    "\n",
    "# Get confidence intervals of  predictions\n",
    "confidence_intervals = one_step_forecast.conf_int()\n",
    "\n",
    "# Select lower and upper confidence limits\n",
    "lower_limits = confidence_intervals.loc[:,'lower close']\n",
    "upper_limits = confidence_intervals.loc[:,'upper close']\n",
    "\n",
    "# Print best estimate  predictions\n",
    "print(mean_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting one-step-ahead predictions\n",
    "\n",
    "Now that you have your predictions on the Amazon stock, you should plot these predictions to see how you've done.\n",
    "\n",
    "You made predictions over the latest 30 days of data available, always forecasting just one day ahead. By evaluating these predictions you can judge how the model performs in making predictions for just the next day, where you don't know the answer.\n",
    "\n",
    "The lower_limits, upper_limits and amazon DataFrames as well as your mean prediction mean_forecast that you created in the last exercise are available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the amazon data\n",
    "plt.plot(amazon.index, amazon, label='observed')\n",
    "\n",
    "# plot your mean predictions\n",
    "plt.plot(mean_forecast.index, mean_forecast, color='r', label='forecast')\n",
    "\n",
    "# shade the area between your confidence limits\n",
    "plt.fill_between(lower_limits.index, lower_limits,\n",
    "\t\t upper_limits, color='pink')\n",
    "\n",
    "# set labels, legends and show plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amazon Stock Price - Close USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dynamic forecasts\n",
    "\n",
    "Now lets move a little further into the future, to dynamic predictions. What if you wanted to predict the Amazon stock price, not just for tomorrow, but for next week or next month? This is where dynamical predictions come in.\n",
    "\n",
    "Remember that in the video you learned how it is more difficult to make precise long-term forecasts because the shock terms add up. The further into the future the predictions go, the more uncertain. This is especially true with stock data and so you will likely find that your predictions in this exercise are not as precise as those in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "dynamic_forecast = results.get_prediction(start=-30, dynamic=True)\n",
    "\n",
    "# Extract prediction mean\n",
    "mean_forecast = dynamic_forecast.predicted_mean\n",
    "\n",
    "# Get confidence intervals of predictions\n",
    "confidence_intervals = dynamic_forecast.conf_int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting dynamic forecasts\n",
    "\n",
    "Time to plot your predictions. Remember that making dynamic predictions, means that your model makes predictions with no corrections, unlike the one-step-ahead predictions. This is kind of like making a forecast now for the next 30 days, and then waiting to see what happens before comparing how good your predictions were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the amazon data\n",
    "plt.plot(amazon.index, amazon, label='observed')\n",
    "\n",
    "# plot your mean forecast\n",
    "plt.plot(mean_forecast.index, mean_forecast, color='r', label='forecast')\n",
    "\n",
    "# shade the area between your confidence limits\n",
    "plt.fill_between(lower_limits.index, lower_limits, \n",
    "         upper_limits, color='pink')\n",
    "\n",
    "# set labels, legends and show plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amazon Stock Price - Close USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing and fitting ARMA\n",
    "\n",
    "In this exercise you will fit an ARMA model to the Amazon stocks dataset. As you saw before, this is a non-stationary dataset. You will use differencing to make it stationary so that you can fit an ARMA model.\n",
    "\n",
    "In the next section you'll make a forecast of the differences and use this to forecast the actual values.\n",
    "\n",
    "The Amazon stock time series in available in your environment as amazon. The SARIMAX model class is also available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Statespace Model Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  close   No. Observations:                 1258\n",
      "Model:               SARIMAX(2, 0, 2)   Log Likelihood               -5534.654\n",
      "Date:                Wed, 26 Feb 2020   AIC                          11079.308\n",
      "Time:                        14:59:52   BIC                          11104.995\n",
      "Sample:                             0   HQIC                         11088.962\n",
      "                               - 1258                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1         -0.1772      0.103     -1.723      0.085      -0.379       0.024\n",
      "ar.L2          0.7722      0.105      7.352      0.000       0.566       0.978\n",
      "ma.L1          0.1639      0.098      1.669      0.095      -0.029       0.356\n",
      "ma.L2         -0.8184      0.100     -8.210      0.000      -1.014      -0.623\n",
      "sigma2       388.0123      6.039     64.254      0.000     376.177     399.848\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       99.12   Jarque-Bera (JB):              7241.06\n",
      "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.06   Skew:                             0.21\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        14.75\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# Take the first difference of the data\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "amazon_diff = amazon.diff().dropna()\n",
    "\n",
    "# Create ARMA(2,2) model\n",
    "arma = sm.tsa.statespace.SARIMAX(amazon_diff, order=(2,0,2))\n",
    "\n",
    "# Fit model\n",
    "arma_results = arma.fit()\n",
    "\n",
    "# Print fit summary\n",
    "print(arma_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unrolling ARMA forecast\n",
    "\n",
    "Now you will use the model that you trained in the previous exercise arma in order to forecast the absolute value of the Amazon stocks dataset. Remember that sometimes predicting the difference could be enough; will the stocks go up, or down; but sometimes the absolute value is key.\n",
    "\n",
    "The results object from the model you trained in the last exercise is available in your environment as arma_results. The np.cumsum() function and the original DataFrame amazon are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258    359.999387\n",
      "1259    360.587838\n",
      "1260    359.811247\n",
      "1261    360.403300\n",
      "1262    359.698675\n",
      "1263    360.280753\n",
      "1264    359.633468\n",
      "1265    360.197681\n",
      "1266    359.597839\n",
      "1267    360.139847\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Make arma forecast of next 10 differences\n",
    "arma_diff_forecast = arma_results.get_forecast(steps=10).predicted_mean\n",
    "\n",
    "# Integrate the difference forecast\n",
    "arma_int_forecast = np.cumsum(arma_diff_forecast)\n",
    "\n",
    "# Make absolute value forecast\n",
    "arma_value_forecast = arma_int_forecast + amazon.iloc[-1,0]\n",
    "\n",
    "# Print forecast\n",
    "print(arma_value_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an ARIMA model\n",
    "\n",
    "In this exercise you'll learn how to be lazy in time series modeling. Instead of taking the difference, modeling the difference and then integrating, you're just going to lets statsmodels do the hard work for you.\n",
    "\n",
    "You'll repeat the same exercise that you did before, of forecasting the absolute values of the Amazon stocks dataset, but this time with an ARIMA model.\n",
    "\n",
    "A subset of the stocks dataset is available in your environment as amazon and so is the SARIMAX model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259    360.000712\n",
      "1260    360.587971\n",
      "1261    359.812499\n",
      "1262    360.403538\n",
      "1263    359.699848\n",
      "1264    360.281079\n",
      "1265    359.634565\n",
      "1266    360.198081\n",
      "1267    359.598864\n",
      "1268    360.140314\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create ARIMA(2,1,2) model\n",
    "arima = sm.tsa.statespace.SARIMAX(amazon, order=(2,1,2))\n",
    "\n",
    "# Fit ARIMA model\n",
    "arima_results = arima.fit()\n",
    "\n",
    "# Make ARIMA forecast of next 10 values\n",
    "arima_value_forecast = arima_results.get_forecast(steps=10).predicted_mean\n",
    "\n",
    "# Print forecast\n",
    "print(arima_value_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
